# 毕设

​ **用心规范讲究，语言文字可能行云流水、表达准确、恰到好处，让人如沐春风。**

`conda -pytorch`

## Multi-Modality Fusion

```python
def __init__(self, num_classes=21, pretrained=False):
        super(unet, self).__init__()
        # 模态A的编码器 (VGG16)
        self.encoder_A = VGG16(pretrained=pretrained)
        # 模态B的编码器 (ResNet50)
        self.encoder_B = resnet50(pretrained=pretrained)
```

代码段中，通过`self.encoder = resnet50(pretrained=pretrained)`这一行将 ResNet50 设置为 U-Net 网络的编码器部分，作为多模态输入网络中的一个编码器。

关于`pretrained`参数设置为`True`和`False`的区别：

- **`pretrained=True`**: 当设置为`True`时，加载的 ResNet50 模型将使用在大规模数据集（如 ImageNet）上预训练得到的权重。这意味着模型已经学习了从大量图像中提取特征的能力，这些特征不仅多样且复杂，对于新的、特别是数据量较小的任务，可以显著提高模型的泛化能力和性能。预训练模型作为起点，可以加速收敛并提高最终模型在特定任务上的性能，这是迁移学习的一种形式。
- **`pretrained=False`**: 当设置为`False`时，模型的权重将被随机初始化，而不是使用预训练的权重。这意味着在训练开始时，模型没有学习到任何之前的知识，所有的学习都将从头开始。对于数据量足够大、且分布与预训练模型所用数据集差异较大的任务，从头开始训练可能是必要的。然而，通常来说，这会需要更长的时间来训练模型，并且模型达到较高性能的难度也会增加。

## 编码器的特征提取尺寸和通道数

### VGG16

VGG16 模型的特征提取过程如下：

1. 输入图像大小为`512x512x3`。
2. 通过两个卷积层（64 通道），尺寸不变，`512x512x64`。√
3. 经过第一个最大池化层，尺寸减半，`256x256x64`
4. 通过两个卷积层（128 通道），尺寸不变，`256x256x128`。
5. 经过第二个最大池化层，尺寸减半，`128x128x128`
6. 通过三个卷积层（256 通道），尺寸不变，`128x128x256`。
7. 经过第三个最大池化层，尺寸减半，`64x64x256`
8. 通过三个卷积层（512 通道），尺寸不变，`64x64x512`。
9. 经过第四个最大池化层，尺寸减半，`32x32x512`
10. 通过三个卷积层（512 通道），尺寸不变，`32x32x512`。
11. 经过第五个最大池化层，尺寸减半，`16x16x512`。

### ResNet50

ResNet50 模型的特征提取过程如下：

1. 输入图像大小为`512x512x3`。
2. 通过一个卷积层（64 通道），尺寸减半，`256x256x64`。
3. 经过最大池化层，尺寸减半，`128x128x64`。
4. 第一层（layer1），不改变尺寸，`128x128x256`。
5. 第二层（layer2），尺寸减半，`64x64x512`。
6. 第三层（layer3），尺寸减半，`32x32x1024`。
7. 第四层（layer4），尺寸减半，`16x16x2048`。

### 特征图尺寸总结

- **VGG16** 的输出特征图尺寸为`16x16x512`（在最后一个最大池化层之后）。
- **ResNet50** 的输出特征图尺寸为`16x16x2048`（在 layer4 之后）。

对于在你的 Unet 模型中调整`in_filters_A`、`in_filters_B`及`out_filters`的值，你应该根据这两个模型输出的特征图的通道数进行调整

##fscore 评估
这些值是在评估模型性能时计算 F-score 的关键组成部分。F-score 是一个衡量模型精确度和召回率平衡的指标，特别适用于数据不平衡的情况。它的计算公式如下：

\[ F\_{\beta} = (1 + \beta^2) \cdot \frac{\text{precision} \cdot \text{recall}}{(\beta^2 \cdot \text{precision}) + \text{recall}} \]

其中，

- **精确度（precision）**是真正例（TP）占所有被识别为正例（TP+FP）的比例，计算公式为 \(\text{precision} = \frac{TP}{TP + FP}\)。
- **召回率（recall）**是真正例（TP）占所有实际正例（TP+FN）的比例，计算公式为 \(\text{recall} = \frac{TP}{TP + FN}\)。
- **\(\beta\)** 是一个权衡精确度和召回率的因子，\(\beta = 1\)时，精确度和召回率同等重要。

在您提供的输出中，每一行都给出了一个批次的 TP（真正例）、FP（假正例）和 FN（假负例）的值，以及基于这些值计算出的 F-score。值得注意的是，FN（假负例）在所有情况下都是 0，这意味着模型没有漏检任何正例，但这也可能指示模型过于乐观地将太多样本预测为正类，从而导致高 FP（假正例）。

这些值的用途包括：

- **性能评估**：通过计算 F-score，您可以量化模型在处理正类样本方面的效能，特别是在正负样本不平衡的数据集上。
- **模型调优**：通过分析 TP、FP 和 FN 的值，您可以了解模型的行为（例如，是否存在过多的假正例），并据此调整模型参数或数据处理流程，以改善模型性能。
- **比较不同模型**：F-score 提供了一个统一的指标来比较不同模型或配置下的性能，帮助您选择最佳模型。

最后，F-score 的值通常介于 0 到 1 之间，值越高表示模型性能越好。在您的输出中，F-score 的值变化表明模型在不同批次的表现有所不同，这是模型训练过程中常见的现象。

### 使用不同分割标签的情况(下一步的改进策略 1)

Q: 那多模态图像分割时，也可以对不同模态图用不同的分割标签吗？我在 Unet 网络把输入图像的特征图都融合到一起了，还能实现不同模态使用不同的分割标签么？

1. 不同模态关注不同结构：如果不同模态的图像关注的解剖结构或病变不同，可能需要为它们分别使用不同的分割标签。例如，在一个综合性的研究中，MRI 图像用于分割脑组织，而 PET 图像用于识别代谢活跃区域，这两种模态关注的目标不同，因此可能需要不同的分割标签。
2. 模态特异性分割任务：在某些特定的医学研究或临床应用中，不同模态的图像可能被用来研究或诊断不同的疾病状态或特征，这时也可能需要为每种模态指定特定的分割标签。
   实现方法
   即使在 U-Net 网络中已经将不同模态的图像特征图融合到一起，仍然可以实现使用不同分割标签的目标，但这需要一些特定的设计考虑：
   分支结构：可以在特征融合之前或之后设计分支结构，使网络能够针对不同的模态输出不同的分割图。这种设计允许网络在共享一部分特征提取过程的同时，针对不同模态的特定特征进行优化分割。
   多任务学习：将多模态分割任务视为多任务学习问题，其中每种模态的分割任务是一个子任务。网络可以通过共享一些底层的特征提取层，同时为每个子任务设计特定的输出层，以实现对不同模态使用不同分割标签的目标。
   注意力机制：利用注意力机制来引导网络关注不同模态图像中与其分割标签最相关的特征。这种方法可以在特征融合后的网络部分实现，通过动态调整不同模态特征的权重，使网络能够更好地适应每种模态的分割任务。
   注意事项
   数据标注成本：为不同模态图像使用不同的分割标签可能会增加数据标注的工作量和成本，因为需要为每种模态单独准备精确的标签。
   模型复杂度：设计能够处理不同分割标签的多模态分割网络可能会增加模型的复杂度，这需要在模型设计时考虑计算资源和效率。
   性能评估：使用不同分割标签时，需要为每种模态分别设计评估指标，以准确评估模型在各个分割任务上的性能。
   总之，虽然多模态图像分割通常采用共用一套分割标签的方法，但根据特定需求，使用不同分割标签也是可行的。这需要通过精心设计网络架构和训练策略来实现。

### loss 值评估

这里的三种损失函数分别是交叉熵损失（CE Loss）、Focal Loss 和 Dice Loss。它们在深度学习中常用于不同类型的任务，如分类、目标检测和分割。这些损失函数各有优势和缺点：
交叉熵损失（CE Loss）：用于多分类任务，通过比较模型输出的概率分布与真实标签的分布来计算损失。优势是易于优化和计算，但对于类别不平衡的数据集可能存在问题。
Focal Loss：专门设计用于解决类别不平衡问题，通过减小易分类样本的权重来关注困难样本，有助于提高模型在少数类别上的性能。然而，对于一些任务可能需要调整参数以获得最佳效果。
Dice Loss：常用于图像分割任务，通过比较模型输出的分割结果与真实标签的重叠程度来计算损失。优势是对于不平衡数据集效果较好，但可能对边界像素敏感。
每种损失函数适用于不同的场景，选择合适的损失函数取决于任务的性质和数据集的特点。在实际应用中，通常需要根据具体情况进行选择和调整，以获得最佳的训练效果

当涉及到图像分割任务时，Dice Loss 是一种常用的损失函数。它的计算方式是通过比较模型预测的分割结果与真实标签之间的重叠程度来衡量损失。具体来说，Dice Loss 计算的是预测结果和真实标签的交集与它们的并集之间的相似度。
Dice Loss 在处理不平衡数据集时表现较好，因为它更关注于类别之间的重叠部分，而不是简单地计算整体像素级别的差异。这使得模型更加专注于正确预测重要区域，而不是被大量背景像素影响。
然而，Dice Loss 可能对边界像素比较敏感，这意味着在边界处的预测可能会受到更大的影响，导致一些细微的误差。因此，在使用 Dice Loss 时，需要注意调整模型的参数和训练策略，以平衡对不同区域的关注，从而获得更好的分割效果。

Q：对于 loss 值计算对象的一点解释。
loss 的计算分为两部分，一部分使用 pngs，另一部分使用 labels。这两个变量代表不同的数据，具体区别如下：
pngs：通常指的是经过预处理（如二值化）后的图像数据。在这个上下文中，pngs 可能是经过特定处理（例如，将像素值小于等于 127.5 的设置为 1）的图像标签，用于计算 Focal_Loss 或 CE_Loss（交叉熵损失）。这种处理方式适用于分类任务，特别是在处理图像分割任务时，标签经常需要被转换成特定的格式以适应损失函数的要求。
labels：则可能指的是原始的、未经处理的图像标签数据。在 Dice_loss 的计算中使用 labels 可能意味着这个损失函数需要原始的标签数据格式。Dice_loss 通常用于图像分割任务，用于衡量预测分割和真实分割之间的相似度，这要求输入的标签保持其原始的形态以准确计算分割的重叠区域。
总结来说，pngs 和 labels 的区别在于它们代表的数据处理方式不同，pngs 可能是经过预处理的标签数据，适用于计算 Focal_Loss 或 CE_Loss，而 labels 可能是原始的标签数据，用于计算 Dice_loss。这种设计允许模型同时利用不同类型的损失函数，从而在训练过程中考虑到不同方面的优化目标，例如，既关注类别的准确预测，也关注分割边界的精确匹配。

### batch_size

batch_size 指的是每次模型训练时同时输入模型的样本数量。它在深度学习中起着重要作用：
加速训练：通过同时处理多个样本，可以利用硬件加速器（如 GPU）的并行计算能力，从而加快模型训练速度。
内存利用：较大的 batch_size 可以更充分地利用硬件资源，减少内存占用和数据传输时间，提高训练效率。
稳定训练：较大的 batch_size 可以提供更稳定的梯度估计，减少随机性，有助于模型更快地收敛。
泛化能力：适当的 batch_size 可以帮助模型更好地泛化到未见过的数据，减少过拟合的风险。
然而，选择合适的 batch_size 也需要考虑硬件资源、模型复杂度和数据集大小等因素。过大的 batch_size 可能导致内存不足，过小的 batch_size 可能导致训练效率低下。因此，在实际应用中，需要根据具体情况进行调整，以获得最佳的训练效果。
